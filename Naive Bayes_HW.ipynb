{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (20% credit)\n",
    "\n",
    "Assume you have a data set as below. It contains records of cars with three features: the type of the car (sports(1) or SUV(2)), the color of the car (red(1) or yellow(2)), and the origin of the car (domestic(1) or imported(2)). And the labels for the data are: stolen(1) and not(0). \n",
    "\n",
    "#### Questions:\n",
    "\n",
    "a) Calculate the following sample probabilities:\n",
    "P(Red|Stolen), P(SUV|Stolen), P(Domestic|Stolen), P(Red|Not Stolen) , P(SUV|Not Stolen), and P(Domestic|Not Stolen)\n",
    "\n",
    "b) Suggest a classification for a red, domestic SUV - whether it will be stolen or not - using Naive Bayes classifier. \n",
    "\n",
    "Please perform all the necessary computations \"by hands\" rather than using python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "y=[1,0,1,0,1,0,1,0,0,1]\n",
    "X=[[1,1,1,2,2,2,2,2,1,1],[1,1,1,1,1,2,2,2,2,1],[1,1,1,1,2,2,2,1,2,2]]\n",
    "data=[y]+X\n",
    "data=pd.DataFrame(data).T\n",
    "data.columns=['Stolen?','Color','Type','Origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stolen?</th>\n",
       "      <th>Color</th>\n",
       "      <th>Type</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stolen?  Color  Type  Origin\n",
       "0        1      1     1       1\n",
       "1        0      1     1       1\n",
       "2        1      1     1       1\n",
       "3        0      2     1       1\n",
       "4        1      2     1       2\n",
       "5        0      2     2       2\n",
       "6        1      2     2       2\n",
       "7        0      2     2       1\n",
       "8        0      1     2       2\n",
       "9        1      1     1       2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\n",
    "P(Red|Yes)=3/5=0.6 \n",
    "\n",
    "P(Red|No)= 2/5=0.4\n",
    "\n",
    "P(SUV|Yes)=1/5=0.2 \n",
    "\n",
    "P(SUV|No) =3/5=0.6\n",
    "\n",
    "P(Domestic|Yes)=2/5=0.4\n",
    "\n",
    "P(Domestic|No) =3/5=0.6\n",
    "\n",
    "(b)\n",
    "\n",
    "P(Yes|Red,SUV,Domestic)~P(Yes) * P(Red | Yes) * P(SUV | Yes) * P(Domestic|Yes)\n",
    "\n",
    "=0.5*0.6*0.2*0.4=0.008\n",
    "\n",
    "P(No) * P(Red | No) * P(SUV | No) * P (Domestic | No)\n",
    "\n",
    "=0.5*0.6 *0.6 *0.6 =0.108\n",
    "\n",
    "Answer: No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (25% credit)\n",
    "Consider a following Guassian Naive Bayes problem.\n",
    "We use eight factors to predict if people have diabetes or not. The variabls are:\n",
    "\n",
    "y: The label (0 - no diabetes, 1 - diabetes)\n",
    "\n",
    "t_pre: Number of times pregnant\n",
    "\n",
    "glu: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "\n",
    "blood_p: Diastolic blood pressure (mm Hg)\n",
    "\n",
    "triceps: Triceps skin fold thickness (mm)\n",
    "\n",
    "serum: 2-Hour serum insulin (mu U/ml)\n",
    "\n",
    "b_m: Body mass index (weight in kg/(height in m)^2)\n",
    "\n",
    "pedigree_f: Diabetes pedigree function\n",
    "\n",
    "age: Age (years)\n",
    "#### ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "a)Train the classifier: use the training data to estimate prior probabilities $P(y=b)$ as well as the parameters (mean and standard deviation) of the sample distributions $P(x_i|y=b)$.\n",
    "\n",
    "b)Perform the classification for the test sample. \n",
    "\n",
    "c)Compare your result to y_test and report the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import random\n",
    "#import shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_train=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/session4/HW/dia_train.csv\") \n",
    "y_train=data_train.iloc[:,1] \n",
    "X_train=data_train.iloc[:,2:] \n",
    "\n",
    "data_test=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/session4/HW/dia_test.csv\")\n",
    "y_test=data_test.iloc[:,1]\n",
    "X_test=data_test.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNaiveBayes(trainData):\n",
    "  #training Gausian Naive Bayes Classifier\n",
    "  tY=trainData.loc[:,trainData.columns[0]]\n",
    "  ind1=tY==0 #Need to change to 0, since my classes are 0 and 1\n",
    "  ind2=tY==1\n",
    "  dp=pd.DataFrame(columns=trainData.columns, index=['mu1','sigma1','mu2','sigma2'])\n",
    "  dp[trainData.columns[0]]['mu1']=1.0*sum(ind1)/len(trainData.index)\n",
    "  dp[trainData.columns[0]]['mu2']=1.0*sum(ind2)/len(trainData.index)\n",
    "  for i in trainData.columns[1:]:\n",
    "    dp.loc['mu1',i]=(trainData[i][ind1]).mean()\n",
    "    dp.loc['sigma1',i]=(trainData[i][ind1]).std()\n",
    "    dp.loc['mu2',i]=(trainData[i][ind2]).mean()\n",
    "    dp.loc['sigma2',i]=(trainData[i][ind2]).std()\n",
    "  return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Modifided for the zero sigmas !!(This should lead big difference if sample is small!)\n",
    "def classifyNaiveBayes(classData,dp):\n",
    "  #classifying using trained Gausian Naive Bayes Classifier\n",
    "  Y=classData.loc[:,classData.columns[0]]*0\n",
    "  for j in classData.index:\n",
    "    P1=dp[classData.columns[0]]['mu1'];\n",
    "    P2=dp[classData.columns[0]]['mu1'];\n",
    "    for i in classData.columns[1:]:\n",
    "        if dp[i]['sigma1']==0:\n",
    "            #when our sample is very small, how to set this sigma?? if all zeros??\n",
    "            P1=P1*stats.norm.pdf(classData[i][j], loc=dp[i]['mu1'],scale=0.5) # set 0 to 0.5(maybe need to consider later)\n",
    "        else:\n",
    "            P1=P1*stats.norm.pdf(classData[i][j], loc=dp[i]['mu1'],scale=dp[i]['sigma1'])\n",
    "        \n",
    "        if dp[i]['sigma2']==0:\n",
    "            P2=P2*stats.norm.pdf(classData[i][j], loc=dp[i]['mu2'],scale=0.5)\n",
    "        else:\n",
    "            P2=P2*stats.norm.pdf(classData[i][j], loc=dp[i]['mu2'],scale=dp[i]['sigma2']) \n",
    "    Y[j]=int(P2>P1)\n",
    " \n",
    "\n",
    "  return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>t_pre</th>\n",
       "      <th>glu</th>\n",
       "      <th>blood_p</th>\n",
       "      <th>triceps</th>\n",
       "      <th>serum</th>\n",
       "      <th>b_m</th>\n",
       "      <th>pedigree_f</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mu1</th>\n",
       "      <td>0.699153</td>\n",
       "      <td>2.69091</td>\n",
       "      <td>111.467</td>\n",
       "      <td>69.2061</td>\n",
       "      <td>27.2</td>\n",
       "      <td>127.006</td>\n",
       "      <td>31.7091</td>\n",
       "      <td>0.468685</td>\n",
       "      <td>28.3939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.61006</td>\n",
       "      <td>24.6919</td>\n",
       "      <td>11.7133</td>\n",
       "      <td>10.4369</td>\n",
       "      <td>91.4861</td>\n",
       "      <td>6.33761</td>\n",
       "      <td>0.29175</td>\n",
       "      <td>8.53736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu2</th>\n",
       "      <td>0.300847</td>\n",
       "      <td>4.07042</td>\n",
       "      <td>144.141</td>\n",
       "      <td>74.5634</td>\n",
       "      <td>33.4789</td>\n",
       "      <td>209.211</td>\n",
       "      <td>35.2239</td>\n",
       "      <td>0.639042</td>\n",
       "      <td>35.7887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.51862</td>\n",
       "      <td>30.6265</td>\n",
       "      <td>13.7993</td>\n",
       "      <td>9.7627</td>\n",
       "      <td>126.921</td>\n",
       "      <td>6.25849</td>\n",
       "      <td>0.439042</td>\n",
       "      <td>10.2635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y    t_pre      glu  blood_p  triceps    serum      b_m  \\\n",
       "mu1     0.699153  2.69091  111.467  69.2061     27.2  127.006  31.7091   \n",
       "sigma1       NaN  2.61006  24.6919  11.7133  10.4369  91.4861  6.33761   \n",
       "mu2     0.300847  4.07042  144.141  74.5634  33.4789  209.211  35.2239   \n",
       "sigma2       NaN  3.51862  30.6265  13.7993   9.7627  126.921  6.25849   \n",
       "\n",
       "       pedigree_f      age  \n",
       "mu1      0.468685  28.3939  \n",
       "sigma1    0.29175  8.53736  \n",
       "mu2      0.639042  35.7887  \n",
       "sigma2   0.439042  10.2635  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(a)\n",
    "traindata=pd.concat([y_train,X_train],axis=1)\n",
    "dp=trainNaiveBayes(traindata)\n",
    "dp\n",
    "\n",
    "#P(y=0)=0.699; P(y=1)=0.300; mu and sigma are showed in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   real  predicted\n",
       "0     0          0\n",
       "1     1          1\n",
       "2     1          1\n",
       "3     1          1\n",
       "4     0          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(b) The predicted labels are saved in C. Let's have a look.\n",
    "from scipy import stats\n",
    "\n",
    "testdata=pd.concat([y_test,X_test],axis=1)\n",
    "C=classifyNaiveBayes(testdata,dp)\n",
    "Result_OS=pd.DataFrame([pd.Series.tolist(y_test),pd.Series.tolist(C)]).T\n",
    "\n",
    "Result_OS.columns=['real','predicted']\n",
    "Result_OS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we guessed(OS) correctely by ratio:0.76582278481\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "acc=Result_OS.loc[:,'real']==Result_OS.loc[:,'predicted']\n",
    "print(\"we guessed(OS) correctely by ratio:{0}\".format(1.0*mistake.sum()/len(mistake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (Credit 25%)\n",
    "We have an artificial data set split, while the training set contains both - labeled (Label_train) and unlabeled (Unlabel) data. Column 'y' is the label, and columns '0','1','2' are categorical variables.\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "a) Use the labeled part data_train to predict the labels of X_Label_test, and report the classification accuracy.\n",
    "\n",
    "b) Improve the classification by using the unlabeled data data_Unlabel and the EM algorithm to predict labels of X_Label_test, and report the new accuracy by EM semi-supervised algorithm (use the same convergence criteria as in the lecture notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/session4/HW/EM_train.csv\")\n",
    "y_Label_train=data_train.iloc[:,1] \n",
    "X_Label_train=data_train.iloc[:,2:] \n",
    "\n",
    "data_test=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/session4/HW/EM_test.csv\")\n",
    "y_Label_test=data_test.iloc[:,1]\n",
    "X_Label_test=data_test.iloc[:,2:]\n",
    "\n",
    "data_Unlabel=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/session4/HW/EM_Unlabel.csv\")\n",
    "X_Unlabel=data_Unlabel.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def trainNaiveBayesDiscrete(trainData):\n",
    "  #training discrete Naive Bayes Classifier\n",
    "  tY=trainData.loc[:,trainData.columns[0]]\n",
    "  m=max([trainData[j][i] for j in trainData.columns[1:] for i in trainData.index]) #maximal number of classes in each feature of a training set\n",
    "  #create output data structure for the probabilities\n",
    "  dp=[pd.DataFrame(columns=trainData.columns, index=range(1,m+1)), pd.DataFrame(columns=trainData.columns, index=range(1,m+1))]\n",
    "  #split the training data between two labels\n",
    "  ind1=tY==0\n",
    "  ind2=tY==1\n",
    "  #estimate P(y=b)  \n",
    "  dp[0][trainData.columns[0]][1]=1.0*ind1.sum()/len(trainData.index)\n",
    "  dp[1][trainData.columns[0]][1]=1.0*ind2.sum()/len(trainData.index)\n",
    "  #estimate conditional probabilities P(x|y=b)\n",
    "  for j in trainData.columns[1:]:\n",
    "    for i in range(1,m+1):\n",
    "        dp[0].loc[i,j]=1.0*(trainData[j][ind1]==i).sum()/ind1.sum();\n",
    "        dp[1].loc[i,j]=1.0*(trainData[j][ind2]==i).sum()/ind2.sum();\n",
    "  return dp\n",
    "\n",
    "\n",
    "def classifyNaiveBayesDiscrete(classData,dp):\n",
    "  #classifying using trained discrete Naive Bayes Classifier\n",
    "  Y=classData[classData.columns[0]]*0\n",
    "  for i in classData.index:\n",
    "    P1=dp[0][classData.columns[0]][1];\n",
    "    P2=dp[1][classData.columns[0]][1];\n",
    "    for j in classData.columns[1:]:\n",
    "      P1=P1*dp[0][j][classData[j][i]]\n",
    "      P2=P2*dp[1][j][classData[j][i]]\n",
    "    Y[i]=int(P2>P1) \n",
    "  return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          y    0    1    2\n",
      "1  0.555556    0  0.2    0\n",
      "2       NaN  0.2    0  0.2\n",
      "3       NaN  0.2    0    0\n",
      "4       NaN  0.2  0.2  0.2\n",
      "5       NaN    0    0    0\n",
      "6       NaN  0.4  0.6  0.6\n",
      "          y     0     1     2\n",
      "1  0.444444   0.5  0.25  0.25\n",
      "2       NaN  0.25   0.5   0.5\n",
      "3       NaN     0  0.25     0\n",
      "4       NaN     0     0     0\n",
      "5       NaN  0.25     0     0\n",
      "6       NaN     0     0  0.25\n"
     ]
    }
   ],
   "source": [
    "# get the probability distribution firstly\n",
    "trainData=pd.concat([y_Label_train,X_Label_train],axis=1)\n",
    "dp=trainNaiveBayesDiscrete(trainData)\n",
    "print dp[0]\n",
    "print dp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate the predicted labels:\n",
    "testdata=pd.concat([y_Label_test,X_Label_test],axis=1)\n",
    "C=classifyNaiveBayesDiscrete(testdata,dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We correctly classified 63.8888888889 percents of the trips based on the labeled data only\n"
     ]
    }
   ],
   "source": [
    "# Report the accuracy of prediction\n",
    "acc=format(100.0*sum(C==y_Label_test)/len(y_Label_test))\n",
    "print (\"We correctly classified {0} percents of the trips based on the labeled data only\".format(acc))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation of Expectation-Maximization algorithm for partially labeled data\n",
    "def EM(X_Label,y_Label,X_Unlabel,dp):\n",
    "  t = 0  \n",
    "  haslabels=len(y_Label)>0\n",
    "\n",
    "  while True:\n",
    "    t = t + 1\n",
    "\n",
    "    classData=X_Unlabel\n",
    "    # Now we want to calculate P(y=1|x) and P(y=2|x) for all observations xj. (these are bunch of scalars)\n",
    "    # we need this to calculate new dp. Basically speaking, for every new iteration we need a new dp.\n",
    "\n",
    "    #for y=1 and y=2\n",
    "\n",
    "    p_x_1=[] #unnormalized P(y=1|x)\n",
    "    p_x_2=[] #unnormalized P(y=2|x)\n",
    "    cols=dp[0].columns\n",
    "\n",
    "    for i in classData.index:\n",
    "        P1=dp[0][cols[0]][1];\n",
    "        P2=dp[1][cols[0]][1];\n",
    "        for j in classData.columns:\n",
    "            P1=P1*dp[0][j][classData[j][i]]\n",
    "            P2=P2*dp[1][j][classData[j][i]]\n",
    "        p_x_1.append(P1)\n",
    "        p_x_2.append(P2)\n",
    "\n",
    "    #Rescale p_x_1 and p_x_2:\n",
    "    summ=np.asarray(p_x_1)+np.asarray(p_x_2)\n",
    "    p_x_1_s=np.asarray(p_x_1)/summ\n",
    "    p_x_2_s=np.asarray(p_x_2)/summ\n",
    "    inds_1 = np.where(np.isnan(p_x_1_s))\n",
    "    inds_2 = np.where(np.isnan(p_x_2_s))\n",
    "    p_x_1_s[inds_1]=0.5\n",
    "    p_x_2_s[inds_2]=0.5\n",
    "    #Now let's calculate P(y=1) and P(y=2)\n",
    "    p_1=p_x_1_s.sum()/len(p_x_1_s)\n",
    "    p_2=p_x_2_s.sum()/len(p_x_2_s)\n",
    "\n",
    "\n",
    "    #Now let's calculate the probability distribution of P(xi|y=1) and P(xi|y=2)\n",
    "    \n",
    "    m=max([classData[j][i] for j in classData.columns for i in classData.index]) #maximal number of classes in each feature of a training set\n",
    "\n",
    "    #create output data structure for the probabilities - new iteration\n",
    "    \n",
    "    dp1=[pd.DataFrame(columns=cols, index=range(1,m+1)), pd.DataFrame(columns=cols, index=range(1,m+1))]\n",
    "\n",
    "    #P(y=b)  \n",
    "    dp1[0][cols[0]][1]=p_1\n",
    "    dp1[1][cols[0]][1]=p_2\n",
    "\n",
    "\n",
    "    #estimate conditional probabilities P(x|y=b) -do we add labeled data to fit?\n",
    "\n",
    "    temp=np.concatenate((np.asmatrix(X_Unlabel),np.asarray(pd.DataFrame(p_x_1_s)),np.asarray(pd.DataFrame(p_x_2_s))), axis=1)\n",
    "    temp=pd.DataFrame(temp)\n",
    "    if haslabels:\n",
    "        ######!!! y_Label=0,1,...\n",
    "        temp_l=np.concatenate((np.asmatrix(X_Label),np.asmatrix(1*(y_Label==0)).transpose(),np.asmatrix(1*(y_Label==1)).transpose()),axis=1)\n",
    "        temp_l=pd.DataFrame(temp_l)\n",
    "        pd.concat([temp,temp_l])\n",
    "   \n",
    "\n",
    "    for j in range(1,len(dp[0].T)):\n",
    "        for i in range(len(dp[0])):\n",
    "            ###!!!!not 4,5\n",
    "            dp1[0].iloc[i,j]=temp[temp.iloc[:,j-1]==i+1].iloc[:,-2].sum()/temp.iloc[:,-2].sum()\n",
    "            dp1[1].iloc[i,j]=temp[temp.iloc[:,j-1]==i+1].iloc[:,-1].sum()/temp.iloc[:,-1].sum()\n",
    "\n",
    "        ############################################################################################\n",
    "    # Now we use dp to decide whether to continue our iterations\n",
    "    \n",
    "    if (sum(sum((dp1[0]-dp[0])**2))+sum(sum((dp1[1]-dp[1])**2)))<0.001: #if dp does not change much\n",
    "        break\n",
    "    else: \n",
    "        dp=dp1  #save new dp and perform next iteration\n",
    "\n",
    "        \n",
    "    ###############################################################################################\n",
    "        #Calculate the log-likelihood\n",
    "        \n",
    "        L=0\n",
    "        \n",
    "        for i in classData.index:\n",
    "            P1=dp[0][cols[0]][1];\n",
    "            P2=dp[1][cols[0]][1];\n",
    "            for j in classData.columns:\n",
    "                P1=P1*dp[0][j][classData[j][i]]\n",
    "                P2=P2*dp[1][j][classData[j][i]]\n",
    "            temp=math.log(P1+P2)\n",
    "            L=L+temp\n",
    "        if haslabels: \n",
    "            ########\n",
    "          for i in X_Label.index:\n",
    "            yi=y_Label[i]\n",
    "            P=dp[yi][cols[0]][1];\n",
    "            for j in X_Label.columns:\n",
    "                P=P*dp[yi][j][X_Label[j][i]]\n",
    "            L=L+math.log(P)\n",
    "        \n",
    "        print (\"Iteration {0}: log maximum liklihood = {1}\".format(t,L))   \n",
    "        \n",
    "        \n",
    "  return dp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: log maximum liklihood = -590.452072842\n",
      "Iteration 2: log maximum liklihood = -572.346722303\n",
      "Iteration 3: log maximum liklihood = -559.190769042\n",
      "Iteration 4: log maximum liklihood = -556.633109435\n",
      "Iteration 5: log maximum liklihood = -556.067798435\n",
      "After EM we correctly classified 94.4444444444 percents of the trips\n"
     ]
    }
   ],
   "source": [
    "#perform EM estimation for theta. dp is taken from part a.\n",
    "dpEM=EM(X_Label_train,y_Label_train,X_Unlabel,dp)\n",
    "#OS test\n",
    "C=classifyNaiveBayesDiscrete(testdata,dpEM) #classify test data with a new theta given by EM\n",
    "acc=100.0*sum(C==y_Label_test)/len(y_Label_test)\n",
    "print (\"After EM we correctly classified {0} percents of the trips\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (Credit 30%)\n",
    "For the similar artifitial data uploaded below:\n",
    "\n",
    "#### Question: \n",
    "\n",
    "a) Apply the EM algorithm (no observed labels, random initial choice of $\\theta$) for clustering the data records into two clusters. Report your result (a vector of cluster numbers for each data record). \n",
    "\n",
    "b) Repeat the clustering 10 times with different random choices of $\\theta$ and analyze the stability of the clustering (matching labels accross different clusterings (use the choice of 0 and 1 labels best matching the previous clustering), estimate average label and its standard error for each record)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/session4/HW/EM_Cluster.csv\")\n",
    "X=data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: log maximum liklihood = -547.708551189\n",
      "Iteration 2: log maximum liklihood = -543.632550236\n",
      "Iteration 3: log maximum liklihood = -539.300168666\n",
      "Iteration 4: log maximum liklihood = -535.227521656\n",
      "Iteration 5: log maximum liklihood = -532.224841652\n",
      "Iteration 6: log maximum liklihood = -530.477702801\n",
      "Iteration 7: log maximum liklihood = -529.30668097\n",
      "Iteration 8: log maximum liklihood = -528.179309407\n",
      "Iteration 9: log maximum liklihood = -526.70959117\n",
      "Iteration 10: log maximum liklihood = -524.452440999\n",
      "Iteration 11: log maximum liklihood = -521.449758353\n",
      "Iteration 12: log maximum liklihood = -518.122329914\n",
      "Iteration 13: log maximum liklihood = -513.845631444\n",
      "Iteration 14: log maximum liklihood = -509.617359123\n",
      "Iteration 15: log maximum liklihood = -507.615671708\n",
      "Iteration 16: log maximum liklihood = -507.094427927\n",
      "0     0\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    0\n",
      "11    0\n",
      "12    1\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "16    0\n",
      "17    0\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "22    1\n",
      "23    1\n",
      "24    1\n",
      "25    0\n",
      "26    0\n",
      "27    1\n",
      "28    0\n",
      "29    1\n",
      "30    1\n",
      "31    1\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#(a)\n",
    "# Generate a random theta\n",
    "b=np.random.uniform(0,1,len(dp[0]))\n",
    "b=np.asarray(b)/float(np.asarray(b).sum())\n",
    "dp[0].iloc[0,0]=np.random.uniform(0,1)\n",
    "dp[1].iloc[0,0]=dp[1].iloc[0,0]=1-dp[0].iloc[0,0]\n",
    "for j in range(1,len(dp[0].T)):\n",
    "    dp[0].iloc[:,j]=b\n",
    "for j in range(1,len(dp[1].T)):\n",
    "    b=np.random.uniform(0,1,len(dp[1]))\n",
    "    b=np.asarray(b)/float(np.asarray(b).sum())\n",
    "    dp[1].iloc[:,j]=b\n",
    "#perform EM estimaton for theta\n",
    "dpEM=EM([],[],X_Unlabel,dp)\n",
    "#Write down the clustering result in C\n",
    "C=classifyNaiveBayesDiscrete(testdata,dpEM) \n",
    "print C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: log maximum liklihood = -551.622252386\n",
      "Iteration 2: log maximum liklihood = -549.572758914\n",
      "Iteration 3: log maximum liklihood = -547.722997458\n",
      "Iteration 4: log maximum liklihood = -546.066376714\n",
      "Iteration 5: log maximum liklihood = -544.699060641\n",
      "Iteration 6: log maximum liklihood = -543.408365954\n",
      "Iteration 7: log maximum liklihood = -541.87423782\n",
      "Iteration 8: log maximum liklihood = -540.017645068\n",
      "Iteration 9: log maximum liklihood = -537.828806638\n",
      "Iteration 10: log maximum liklihood = -534.98176845\n",
      "Iteration 11: log maximum liklihood = -530.502472417\n",
      "Iteration 12: log maximum liklihood = -523.009794221\n",
      "Iteration 13: log maximum liklihood = -514.358299491\n",
      "Iteration 14: log maximum liklihood = -509.073949214\n",
      "Iteration 15: log maximum liklihood = -506.885051976\n",
      "Iteration 16: log maximum liklihood = -505.963292913\n",
      "Iteration 1: log maximum liklihood = -552.5032281\n",
      "Iteration 2: log maximum liklihood = -548.16277931\n",
      "Iteration 3: log maximum liklihood = -538.867842774\n",
      "Iteration 4: log maximum liklihood = -524.629183517\n",
      "Iteration 5: log maximum liklihood = -514.206344587\n",
      "Iteration 6: log maximum liklihood = -510.09706911\n",
      "Iteration 7: log maximum liklihood = -508.627808105\n",
      "Iteration 8: log maximum liklihood = -508.047286852\n",
      "Iteration 1: log maximum liklihood = -552.358996103\n",
      "Iteration 2: log maximum liklihood = -542.947102633\n",
      "Iteration 3: log maximum liklihood = -525.777355595\n",
      "Iteration 4: log maximum liklihood = -512.131396301\n",
      "Iteration 5: log maximum liklihood = -507.738270772\n",
      "Iteration 6: log maximum liklihood = -505.868916891\n",
      "Iteration 1: log maximum liklihood = -530.15276331\n",
      "Iteration 2: log maximum liklihood = -513.896757924\n",
      "Iteration 3: log maximum liklihood = -508.407305881\n",
      "Iteration 4: log maximum liklihood = -506.530488184\n",
      "Iteration 5: log maximum liklihood = -505.470697907\n",
      "Iteration 6: log maximum liklihood = -504.871191453\n",
      "Iteration 1: log maximum liklihood = -547.61790953\n",
      "Iteration 2: log maximum liklihood = -536.881091388\n",
      "Iteration 3: log maximum liklihood = -524.094947988\n",
      "Iteration 4: log maximum liklihood = -515.34160503\n",
      "Iteration 5: log maximum liklihood = -511.271679056\n",
      "Iteration 6: log maximum liklihood = -509.099785973\n",
      "Iteration 7: log maximum liklihood = -507.42424658\n",
      "Iteration 8: log maximum liklihood = -506.084408345\n",
      "Iteration 9: log maximum liklihood = -505.186291878\n",
      "Iteration 1: log maximum liklihood = -544.122264892\n",
      "Iteration 2: log maximum liklihood = -535.812139475\n",
      "Iteration 3: log maximum liklihood = -528.692747992\n",
      "Iteration 4: log maximum liklihood = -522.234591364\n",
      "Iteration 5: log maximum liklihood = -515.398630926\n",
      "Iteration 6: log maximum liklihood = -510.976364492\n",
      "Iteration 7: log maximum liklihood = -509.263396013\n",
      "Iteration 8: log maximum liklihood = -508.126066551\n",
      "Iteration 9: log maximum liklihood = -507.056882141\n",
      "Iteration 1: log maximum liklihood = -550.641109566\n",
      "Iteration 2: log maximum liklihood = -546.898317893\n",
      "Iteration 3: log maximum liklihood = -543.583893658\n",
      "Iteration 4: log maximum liklihood = -539.225763601\n",
      "Iteration 5: log maximum liklihood = -532.462023562\n",
      "Iteration 6: log maximum liklihood = -523.759206437\n",
      "Iteration 7: log maximum liklihood = -516.550426384\n",
      "Iteration 8: log maximum liklihood = -513.386610639\n",
      "Iteration 9: log maximum liklihood = -512.071793813\n",
      "Iteration 10: log maximum liklihood = -511.039679959\n",
      "Iteration 1: log maximum liklihood = -545.074050979\n",
      "Iteration 2: log maximum liklihood = -527.658541655\n",
      "Iteration 3: log maximum liklihood = -512.927237542\n",
      "Iteration 4: log maximum liklihood = -507.973613921\n",
      "Iteration 5: log maximum liklihood = -506.706949894\n",
      "Iteration 6: log maximum liklihood = -505.998456794\n",
      "Iteration 1: log maximum liklihood = -550.759915428\n",
      "Iteration 2: log maximum liklihood = -542.689779769\n",
      "Iteration 3: log maximum liklihood = -530.06477404\n",
      "Iteration 4: log maximum liklihood = -518.064031476\n",
      "Iteration 5: log maximum liklihood = -512.735264602\n",
      "Iteration 6: log maximum liklihood = -511.089460869\n",
      "Iteration 7: log maximum liklihood = -510.073132941\n",
      "Iteration 8: log maximum liklihood = -508.806822133\n",
      "Iteration 9: log maximum liklihood = -507.244578486\n",
      "Iteration 10: log maximum liklihood = -505.874383869\n",
      "Iteration 11: log maximum liklihood = -505.091345416\n",
      "Iteration 1: log maximum liklihood = -530.053762429\n",
      "Iteration 2: log maximum liklihood = -510.965290431\n",
      "Iteration 3: log maximum liklihood = -505.295134393\n",
      "Iteration 4: log maximum liklihood = -504.508500397\n"
     ]
    }
   ],
   "source": [
    "# b) Do it 10 times. And compare the clustering result\n",
    "answer=[]\n",
    "for i in range(10):\n",
    "#initialize theta randomly\n",
    "    b=np.random.uniform(0,1,len(dp[0]))\n",
    "    b=np.asarray(b)/float(np.asarray(b).sum())\n",
    "    dp[0].iloc[0,0]=np.random.uniform(0,1)\n",
    "    dp[1].iloc[0,0]=dp[1].iloc[0,0]=1-dp[0].iloc[0,0]\n",
    "    for j in range(1,len(dp[0].T)):\n",
    "        dp[0].iloc[:,j]=b\n",
    "    for j in range(1,len(dp[1].T)):\n",
    "        b=np.random.uniform(0,1,len(dp[1]))\n",
    "        b=np.asarray(b)/float(np.asarray(b).sum())\n",
    "        dp[1].iloc[:,j]=b\n",
    "    #perform EM estimaton for theta\n",
    "    dpEM=EM([],[],X_Unlabel,dp)\n",
    "    #OS test\n",
    "    C=classifyNaiveBayesDiscrete(testdata,dpEM) #classify test data with a new theta given by EM\n",
    "    answer.append(C.values.tolist())\n",
    "answer=pd.DataFrame(answer).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3  4  5  6  7  8  9\n",
       "0   1  1  1  1  1  1  1  1  0  0\n",
       "1   1  0  1  1  1  1  0  1  0  0\n",
       "2   0  1  0  0  0  0  1  0  1  1\n",
       "3   1  0  1  1  1  1  0  1  0  0\n",
       "4   0  1  0  0  0  0  1  0  1  1\n",
       "5   0  1  0  0  0  0  1  0  1  1\n",
       "6   0  1  0  0  0  0  1  0  1  1\n",
       "7   0  1  0  0  0  0  1  0  1  1\n",
       "8   0  1  0  0  0  0  1  0  1  1\n",
       "9   0  1  0  0  0  0  1  0  1  1\n",
       "10  1  0  1  1  1  1  0  1  0  0\n",
       "11  1  0  1  1  1  1  0  1  0  0\n",
       "12  0  1  0  0  0  0  1  0  1  1\n",
       "13  1  0  1  1  1  1  0  1  0  0\n",
       "14  0  1  0  0  0  0  1  0  1  1\n",
       "15  0  1  0  0  0  0  0  0  1  1\n",
       "16  1  0  1  1  1  1  0  1  0  0\n",
       "17  1  0  1  1  1  1  0  1  0  0\n",
       "18  0  1  0  0  0  0  1  0  1  1\n",
       "19  0  1  0  0  0  0  1  0  1  1\n",
       "20  0  1  0  0  0  0  1  0  1  1\n",
       "21  0  1  0  0  0  0  1  0  1  1\n",
       "22  0  1  0  0  0  0  1  0  1  1\n",
       "23  0  1  0  0  0  0  1  0  1  1\n",
       "24  0  1  0  0  0  0  1  0  1  1\n",
       "25  1  0  1  1  1  1  0  1  0  0\n",
       "26  1  0  1  1  1  1  0  1  0  0\n",
       "27  0  1  0  0  0  0  1  0  1  1\n",
       "28  1  0  1  1  1  1  0  1  0  0\n",
       "29  0  1  0  0  0  0  1  0  1  1\n",
       "30  0  1  0  0  0  0  1  0  1  1\n",
       "31  0  1  0  0  0  0  1  0  1  1\n",
       "32  1  0  1  1  1  1  1  1  0  0\n",
       "33  1  0  1  1  1  1  0  1  0  0\n",
       "34  1  0  1  1  1  1  0  1  0  0\n",
       "35  1  0  1  1  1  1  0  1  0  0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average matching rate between 1-9 times and 0 time, is:1.0\n"
     ]
    }
   ],
   "source": [
    "# Now Let's compare the results from columns 1 to 9 to the result 0 to see the similarity between them.\n",
    "# Remember we reach the results everytime from a random Theta.\n",
    "#(! when we talk about stability of clustering, we want to show the clusters(results) in our \n",
    "#experiments are similar. However,we do not care about the labels of clusters, since we do not\n",
    "#have any labels. So we need to be careful when we compare the results. For example, if we have\n",
    "#four elements and did two experiments, first time the labels=\n",
    "#[0,0,1,1] and the second time the labels=[1,1,0,0], We regard the results are same.)\n",
    "total_accurace=0\n",
    "for i in range(1,10):\n",
    "    temp=(answer.iloc[:,i]-answer.iloc[:,i-1]).abs()\n",
    "    temp=temp.sum()/len(answer)\n",
    "    if temp<0.5:\n",
    "        total_accurace=total_accurace+(1-temp)\n",
    "    else:\n",
    "        total_accurace=total_accurace+temp\n",
    "\n",
    "print(\"the average matching rate between 1-9 times and 0 time, is:{}\".format(1.0*total_accurace/9))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So, our EM cloustering is very stable(by 10 times experient we get same clusters) and we \n",
    "#do not have any errors here in my experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
