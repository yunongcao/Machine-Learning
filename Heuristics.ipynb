{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import random\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train_set = pd.DataFrame.from_csv('sqf_train_cpw.csv', index_col = False)\n",
    "test_set = pd.DataFrame.from_csv('sqf_test_cpw.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join and re-split data to get all categories\n",
    "train_set['set'] = 'train'\n",
    "test_set['set'] = 'test'\n",
    "joined_data = train_set.append(test_set)\n",
    "\n",
    "# select all non-real-valued columns (besides 'set' and 'id') and convert to one-hot encoding\n",
    "col_names = joined_data.columns\n",
    "col_names = col_names.difference(['id', 'set', 'suspect.age', 'suspect.weight', 'suspect.height', 'observation.period'])\n",
    "joined_data = pd.get_dummies(data=joined_data, columns=col_names, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>suspect.age</th>\n",
       "      <th>suspect.height</th>\n",
       "      <th>suspect.weight</th>\n",
       "      <th>observation.period</th>\n",
       "      <th>set</th>\n",
       "      <th>additional.associating_False</th>\n",
       "      <th>additional.associating_True</th>\n",
       "      <th>additional.direction_False</th>\n",
       "      <th>additional.direction_True</th>\n",
       "      <th>...</th>\n",
       "      <th>time.period_1</th>\n",
       "      <th>time.period_2</th>\n",
       "      <th>time.period_3</th>\n",
       "      <th>time.period_4</th>\n",
       "      <th>time.period_5</th>\n",
       "      <th>time.period_6</th>\n",
       "      <th>year_2009</th>\n",
       "      <th>year_2010</th>\n",
       "      <th>year_2011</th>\n",
       "      <th>year_2012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565349</td>\n",
       "      <td>-0.016428</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>-0.372207</td>\n",
       "      <td>-0.024228</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582029</td>\n",
       "      <td>-0.418262</td>\n",
       "      <td>1.007377</td>\n",
       "      <td>-0.719462</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969776</td>\n",
       "      <td>1.389991</td>\n",
       "      <td>-1.605475</td>\n",
       "      <td>-0.372207</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2324214</td>\n",
       "      <td>1.691367</td>\n",
       "      <td>0.680770</td>\n",
       "      <td>-0.372207</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1722977</td>\n",
       "      <td>-0.518721</td>\n",
       "      <td>1.333983</td>\n",
       "      <td>0.148676</td>\n",
       "      <td>-0.225465</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  suspect.age  suspect.height  suspect.weight  observation.period  \\\n",
       "0  1565349    -0.016428        0.027557       -0.372207           -0.024228   \n",
       "1  2582029    -0.418262        1.007377       -0.719462           -0.225465   \n",
       "2  1969776     1.389991       -1.605475       -0.372207           -0.225465   \n",
       "3  2324214     1.691367        0.680770       -0.372207           -0.225465   \n",
       "4  1722977    -0.518721        1.333983        0.148676           -0.225465   \n",
       "\n",
       "     set  additional.associating_False  additional.associating_True  \\\n",
       "0  train                             1                          NaN   \n",
       "1  train                             1                          NaN   \n",
       "2  train                             1                          NaN   \n",
       "3  train                             1                          NaN   \n",
       "4  train                             1                          NaN   \n",
       "\n",
       "   additional.direction_False  additional.direction_True    ...      \\\n",
       "0                           0                          1    ...       \n",
       "1                           0                          1    ...       \n",
       "2                           0                          1    ...       \n",
       "3                           1                          0    ...       \n",
       "4                           1                          0    ...       \n",
       "\n",
       "   time.period_1  time.period_2  time.period_3  time.period_4  time.period_5  \\\n",
       "0              0            NaN            NaN            NaN              0   \n",
       "1              0            NaN            NaN            NaN              1   \n",
       "2              0            NaN            NaN            NaN              0   \n",
       "3              0            NaN            NaN            NaN              0   \n",
       "4              1            NaN            NaN            NaN              0   \n",
       "\n",
       "   time.period_6  year_2009  year_2010  year_2011  year_2012  \n",
       "0              1          1          0        NaN        NaN  \n",
       "1              0          0          1        NaN        NaN  \n",
       "2              1          1          0        NaN        NaN  \n",
       "3              1          0          1        NaN        NaN  \n",
       "4              0          1          0        NaN        NaN  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove redundant columns (binary columns of the form 'variable_False')\n",
    "redundant_cols = []\n",
    "for name in list(joined_data):\n",
    "    if \"False\" in name:\n",
    "        redundant_cols.append(name)\n",
    "joined_data.drop(redundant_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data again\n",
    "train = joined_data.loc[joined_data['set'] == 'train']\n",
    "train = train.drop(['set'], axis=1)\n",
    "test = joined_data.loc[joined_data['set'] == 'test']\n",
    "test = test.drop(['set'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split training data into features and outcome (numpy arrays, to feed to sklearn algorithms)\n",
    "label_train = np.ravel(train[['found.weapon_True']].values)\n",
    "pred_train = train.drop(['id', 'arrested_True', 'found.weapon_True', 'found.gun_True'], axis=1)\n",
    "pred_train = pred_train.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296521, 152)\n"
     ]
    }
   ],
   "source": [
    "# format test data\n",
    "results = test.copy()\n",
    "label_test = np.ravel(test[['found.weapon_True']].values)\n",
    "pred_test = test.drop(['id', 'found.weapon_True', 'arrested_True', 'found.gun_True'], axis=1)\n",
    "feature_names = list(pred_test.columns.values)\n",
    "pred_test = pred_test.values \n",
    "\n",
    "print results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.829250266101\n",
      "0.96460621676\n"
     ]
    }
   ],
   "source": [
    "# fit an L1 penalized logistic regression model\n",
    "logit_classifier = LogisticRegression(penalty=\"l1\", solver='liblinear', verbose=2)\n",
    "logit_classifier.fit(X=pred_train, y=label_train)\n",
    "\n",
    "logit_predictions = logit_classifier.predict_proba(pred_test)[:, 1]\n",
    "results['preds'] = logit_predictions\n",
    "print roc_auc_score(label_test, logit_predictions)\n",
    "\n",
    "logit_predictions_class = logit_classifier.predict(pred_test)\n",
    "print accuracy_score(label_test, logit_predictions_class, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      "  True False False False False False False False False False  True  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False  True False  True False False False False False\n",
      " False  True  True False  True False  True False False  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False  True False False  True  True False False False False False False\n",
      " False False  True  True False False False  True  True  True False False\n",
      " False False  True  True False False False False False False False  True\n",
      " False  True  True False False False False False False False False False\n",
      "  True  True False False]\n"
     ]
    }
   ],
   "source": [
    "# for different threshold values, select the features which remain in the model\n",
    "model = SelectFromModel(logit_classifier, prefit=True, threshold=.5)\n",
    "pred_test_new = model.transform(pred_test)\n",
    "\n",
    "#print pred_test.shape\n",
    "#print pred_test_new.shape\n",
    "print model.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('additional.sights_True', True), ('location.housing_housing', True), ('location.housing_neither', True), ('location.housing_transit', True), ('precinct_9', True), ('precinct_24', True), ('precinct_26', True), ('precinct_41', True), ('precinct_42', True), ('precinct_44', True), ('precinct_46', True), ('precinct_49', True), ('precinct_50', True), ('precinct_52', True), ('precinct_76', True), ('precinct_102', True), ('precinct_105', True), ('precinct_106', True), ('precinct_115', True), ('precinct_120', True), ('stopped.bc.bulge_True', True), ('stopped.bc.casing_True', True), ('stopped.bc.clothing_True', True), ('stopped.bc.object_True', True), ('stopped.bc.other_True', True), ('suspect.race_black', True), ('suspect.race_native.american', True), ('suspect.race_other', True), ('year_2009', True), ('year_2010', True), ('suspect.age', False), ('suspect.height', False), ('suspect.weight', False), ('observation.period', False), ('additional.associating_True', False), ('additional.direction_True', False), ('additional.evasive_True', False), ('additional.highcrime_True', False), ('additional.investigation_True', False), ('additional.other_True', False), ('additional.proximity_True', False), ('additional.report_True', False), ('additional.time_True', False), ('day_Friday', False), ('day_Monday', False), ('day_Saturday', False), ('day_Sunday', False), ('day_Thursday', False), ('day_Tuesday', False), ('day_Wednesday', False), ('inside.outside_True', False), ('month_April', False), ('month_August', False), ('month_December', False), ('month_February', False), ('month_January', False), ('month_July', False), ('month_June', False), ('month_March', False), ('month_May', False), ('month_November', False), ('month_October', False), ('month_September', False), ('officer.uniform_True', False), ('precinct_1', False), ('precinct_5', False), ('precinct_6', False), ('precinct_7', False), ('precinct_10', False), ('precinct_13', False), ('precinct_14', False), ('precinct_17', False), ('precinct_18', False), ('precinct_19', False), ('precinct_20', False), ('precinct_22', False), ('precinct_23', False), ('precinct_25', False), ('precinct_28', False), ('precinct_30', False), ('precinct_32', False), ('precinct_33', False), ('precinct_34', False), ('precinct_40', False), ('precinct_43', False), ('precinct_45', False), ('precinct_47', False), ('precinct_48', False), ('precinct_60', False), ('precinct_61', False), ('precinct_62', False), ('precinct_63', False), ('precinct_66', False), ('precinct_67', False), ('precinct_68', False), ('precinct_69', False), ('precinct_70', False), ('precinct_71', False), ('precinct_72', False), ('precinct_73', False), ('precinct_75', False), ('precinct_77', False), ('precinct_78', False), ('precinct_79', False), ('precinct_81', False), ('precinct_83', False), ('precinct_84', False), ('precinct_88', False), ('precinct_90', False), ('precinct_94', False), ('precinct_100', False), ('precinct_101', False), ('precinct_103', False), ('precinct_104', False), ('precinct_107', False), ('precinct_108', False), ('precinct_109', False), ('precinct_110', False), ('precinct_111', False), ('precinct_112', False), ('precinct_113', False), ('precinct_114', False), ('precinct_122', False), ('precinct_123', False), ('radio.run_True', False), ('stopped.bc.desc_True', False), ('stopped.bc.drugs_True', False), ('stopped.bc.furtive_True', False), ('stopped.bc.lookout_True', False), ('stopped.bc.violent_True', False), ('suspect.build_heavy', False), ('suspect.build_medium', False), ('suspect.build_muscular', False), ('suspect.build_thin', False), ('suspect.build_unknown', False), ('suspect.race_asian', False), ('suspect.race_hispanic', False), ('suspect.race_white', False), ('suspect.sex_female', False), ('suspect.sex_male', False), ('time.period_1', False), ('time.period_2', False), ('time.period_3', False), ('time.period_4', False), ('time.period_5', False), ('time.period_6', False), ('year_2011', False), ('year_2012', False)]\n"
     ]
    }
   ],
   "source": [
    "feature_importances = list(model.get_support())\n",
    "feature_list = []\n",
    "for i in range(0,len(feature_names)):\n",
    "    feature_list.append((feature_names[i], feature_importances[i]))\n",
    "\n",
    "#get the names of the features from the previous cell\n",
    "print sorted(feature_list, reverse=True, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.76393828085\n",
      "[[-3.13929127 -2.34887376  2.72326046  0.55668889  0.90773781]]\n"
     ]
    }
   ],
   "source": [
    "# train a new model based just on features selected above\n",
    "#predictors = ['location.housing_housing', 'location.housing_neither', 'stopped.bc.object_True', 'stopped.bc.bulge_True', 'additional.sights_True']\n",
    "predictors = ['location.housing_housing', 'location.housing_neither','stopped.bc.object_True', 'stopped.bc.bulge_True', 'additional.sights_True']\n",
    "\n",
    "pred_train = train[predictors]\n",
    "pred_train = pred_train.values \n",
    "pred_test = test[predictors]\n",
    "feature_names = list(pred_test.columns.values)\n",
    "pred_test = pred_test.values \n",
    "\n",
    "\n",
    "# How does AUC change as you add/subtract features?\n",
    "\n",
    "logit_classifier_simple = LogisticRegression(solver='liblinear', verbose=2)\n",
    "logit_classifier_simple.fit(X=pred_train, y=label_train)\n",
    "\n",
    "logit_predictions_simple = logit_classifier_simple.predict_proba(pred_test)[:, 1]\n",
    "results['preds_simple'] = logit_predictions_simple\n",
    "print roc_auc_score(label_test, logit_predictions_simple)\n",
    "\n",
    "print logit_classifier_simple.coef_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stopped.bc.object_True  stopped.bc.bulge_True  additional.sights_True  \\\n",
      "0                      0.0                    0.0                     0.0   \n",
      "1                      0.0                    0.0                     0.0   \n",
      "2                      0.0                    0.0                     0.0   \n",
      "3                      0.0                    0.0                     0.0   \n",
      "4                      0.0                    1.0                     0.0   \n",
      "5                      0.0                    0.0                     0.0   \n",
      "6                      0.0                    0.0                     0.0   \n",
      "7                      0.0                    0.0                     1.0   \n",
      "8                      0.0                    0.0                     1.0   \n",
      "9                      0.0                    0.0                     0.0   \n",
      "10                     0.0                    0.0                     0.0   \n",
      "11                     0.0                    0.0                     0.0   \n",
      "12                     0.0                    0.0                     0.0   \n",
      "13                     0.0                    0.0                     0.0   \n",
      "14                     0.0                    0.0                     0.0   \n",
      "15                     0.0                    0.0                     0.0   \n",
      "16                     0.0                    0.0                     0.0   \n",
      "17                     0.0                    0.0                     0.0   \n",
      "18                     0.0                    0.0                     0.0   \n",
      "19                     1.0                    0.0                     0.0   \n",
      "\n",
      "    heuristic_score     preds  \n",
      "0               0.0  0.035829  \n",
      "1               0.0  0.035829  \n",
      "2               0.0  0.035319  \n",
      "3               0.0  0.037047  \n",
      "4               1.0  0.039255  \n",
      "5               0.0  0.026255  \n",
      "6               0.0  0.016312  \n",
      "7               1.0  0.089946  \n",
      "8               1.0  0.097656  \n",
      "9               0.0  0.060778  \n",
      "10              0.0  0.061712  \n",
      "11              0.0  0.009836  \n",
      "12              0.0  0.019586  \n",
      "13              0.0  0.013062  \n",
      "14              0.0  0.018600  \n",
      "15              0.0  0.018854  \n",
      "16              0.0  0.013490  \n",
      "17              0.0  0.003799  \n",
      "18              0.0  0.007666  \n",
      "19              1.0  0.301380  \n"
     ]
    }
   ],
   "source": [
    "# add a column which contains the unit weighted heuristic score derived from the features from the previous cell\n",
    "results['heuristic_score'] = results[['stopped.bc.object_True', 'stopped.bc.bulge_True', 'additional.sights_True']].sum(axis=1)\n",
    "print results[['stopped.bc.object_True', 'stopped.bc.bulge_True', 'additional.sights_True', 'heuristic_score', 'preds']].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rs4606/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/Users/rs4606/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/rs4606/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/rs4606/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/rs4606/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/rs4606/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    210000\n",
      "1.0     84140\n",
      "2.0      2310\n",
      "3.0        71\n",
      "Name: heuristic_score, dtype: int64\n",
      "1.0    0.605088\n",
      "Name: found.weapon_True, dtype: float64\n",
      "0.291787090965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12305a490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBARCXMKAhGRMKcgEBEJcwoCEZEw9/8BxTJW5xv6vFIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12305b250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting question:\n",
    "# Make a recovery plot: if you used the logistic model to rank stops by model-predicted likelihood of weapon recovery, \n",
    "# from highest to lowest, what percent of weapons would you recover if you made the best x percent of stops?\n",
    "# The plot should have percent of stops on the x axis and percent weapons recovered on the y axis\n",
    "\n",
    "# HINTS:\n",
    "# 1) order results by column 'preds'\n",
    "results = results.sort(['preds'], ascending=False)\n",
    "# 2) add a column to results which is the cumulative sum of found.weapon_True\n",
    "plot_data = results[['found.weapon_True', 'preds']]\n",
    "plot_data['weap_sum'] = plot_data['found.weapon_True'].cumsum()\n",
    "# 3) use the above cumulative sum to make a column which shows percent weapons recovered\n",
    "plot_data['weap_perc'] = 100*plot_data['weap_sum']/plot_data['found.weapon_True'].sum()\n",
    "# 4) add a column which counts the stops\n",
    "s = [j for j in range(1,296522)]\n",
    "plot_data['nstop'] = s\n",
    "# 5) use the above stop count column to make a column which shows percent of all stops\n",
    "plot_data['stop_perc'] = 100*plot_data['nstop']/plot_data.shape[0]\n",
    "# 6) restrict to just the columns from 3) and 5), downsample to maybe 1000 rows\n",
    "plot_data = plot_data[['stop_perc', 'weap_perc']]\n",
    "rows = random.sample(plot_data.index, 1000)\n",
    "plot_data = plot_data.ix[rows]\n",
    "# 7) sort everything in ascending order by the column from 5), then plot.\n",
    "plot_data = plot_data.sort(['stop_perc'], ascending=True)\n",
    "plt.figure()\n",
    "plot_data.plot(x='stop_perc', y='weap_perc')\n",
    "\n",
    "\n",
    "\n",
    "###### how does the heuristic model perform??\n",
    "print results['heuristic_score'].value_counts()\n",
    "\n",
    "score_three = results.loc[results['heuristic_score'].isin([1,2,3])]\n",
    "\n",
    "print score_three['found.weapon_True'].value_counts()/results['found.weapon_True'].value_counts()\n",
    "print float(84140 + 2310 + 71)/(84140 + 2310 + 71 + 210000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
