{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train_set = pd.DataFrame.from_csv('sqf_train_cpw.csv', index_col = False)\n",
    "test_set = pd.DataFrame.from_csv('sqf_test_cpw.csv', index_col = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore the data a bit\n",
    "# feature names and number of rows/cols\n",
    "print train_set.columns\n",
    "print train_set.shape\n",
    "\n",
    "# distribution of various features in the training set\n",
    "train_set['year'].value_counts()\n",
    "train_set['found.weapon'].value_counts()\n",
    "train_set['precinct'].value_counts()\n",
    "train_set['suspect.race'].value_counts()\n",
    "\n",
    "# proportion of features in the training set\n",
    "train_set['suspect.race'].value_counts() / np.sum(train_set['suspect.race'].value_counts())\n",
    "train_set['suspect.sex'].value_counts() / np.sum(train_set['suspect.sex'].value_counts())\n",
    "\n",
    "# Warmup question:\n",
    "# which precinct in the training set has the highest percentage of successful stops, i.e. stops where found.weapon==True?\n",
    "\n",
    "temp = train_set.groupby('precinct')\n",
    "precinct_list = []\n",
    "for name, group in temp:\n",
    "    precinct_list.append((name, np.mean(group['found.weapon'])))\n",
    "\n",
    "print sorted(precinct_list, reverse=True, key=lambda x: x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join and re-split data to get all categories\n",
    "train_set['set'] = 'train'\n",
    "test_set['set'] = 'test'\n",
    "joined_data = train_set.append(test_set)\n",
    "\n",
    "# select all non-real-valued columns (besides 'set' and 'id') and convert to one-hot encoding\n",
    "col_names = joined_data.columns\n",
    "col_names = col_names.difference(['id', 'set', 'suspect.age', 'suspect.weight', 'suspect.height', 'observation.period'])\n",
    "joined_data = pd.get_dummies(data=joined_data, columns=col_names, sparse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what does the data look like after converting to one-hot encoding?\n",
    "list(joined_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove redundant columns (binary columns of the form 'variable_False')\n",
    "redundant_cols = []\n",
    "for name in list(joined_data):\n",
    "    if \"False\" in name:\n",
    "        redundant_cols.append(name)\n",
    "joined_data.drop(redundant_cols, inplace=True, axis=1)\n",
    "\n",
    "# verify that redundant columns have been removed\n",
    "list(joined_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data again\n",
    "train = joined_data.loc[joined_data['set'] == 'train']\n",
    "train = train.drop(['set'], axis=1)\n",
    "test = joined_data.loc[joined_data['set'] == 'test']\n",
    "test = test.drop(['set'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split training data into features and outcome (numpy arrays, to feed to sklearn algorithms)\n",
    "label_train = np.ravel(train[['found.weapon_True']].values)\n",
    "pred_train = train.drop(['id', 'arrested_True', 'found.weapon_True', 'found.gun_True'], axis=1)\n",
    "\n",
    "print pred_train.head()\n",
    "pred_train = pred_train.values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format test data\n",
    "results = test.copy()\n",
    "label_test = np.ravel(test[['found.weapon_True']].values)\n",
    "pred_test = test.drop(['id', 'found.weapon_True', 'arrested_True', 'found.gun_True'], axis=1)\n",
    "feature_names = list(pred_test.columns.values)\n",
    "pred_test = pred_test.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model with 500 trees, 4 parallel processes, and 10 min samples to split a node \n",
    "num_trees = 500\n",
    "rf = RandomForestClassifier(n_estimators=num_trees, n_jobs=4, min_samples_split=10, verbose=2, oob_score = True)\n",
    "rf.fit(X=pred_train, y=label_train)\n",
    "\n",
    "# generate predictions and add them to 'results'\n",
    "rf_predictions = rf.predict_proba(pred_test)[:, 1]\n",
    "results['preds'] = rf_predictions\n",
    "\n",
    "# get AUC score (produce probabilistic predictions)\n",
    "print roc_auc_score(label_test, rf_predictions)\n",
    "\n",
    "# get accuracy (predict the class)\n",
    "rf_predictions_class = rf.predict(pred_test)\n",
    "print accuracy_score(label_test, rf_predictions_class, normalize=True)\n",
    "\n",
    "# Questions:\n",
    "# What happens to AUC if I change the target variable to found.gun_True?\n",
    "# What happens to AUC and accuracy if I forgot to take out found.weapon_True from the features?  Why?\n",
    "# How does AUC change if I forgot to remove 'arrested_True'?  Does that mean I should remove it?\n",
    "# What are the most five important features?\n",
    "\n",
    "feature_importances = list(rf.feature_importances_)\n",
    "feature_list = []\n",
    "for i in range(0,len(feature_names)):\n",
    "    feature_list.append((feature_names[i], feature_importances[i]))\n",
    "print sorted(feature_list, reverse=True, key=lambda x: x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting question:\n",
    "# Make a recovery plot: if you used the RF model to rank stops by model-predicted likelihood of weapon recovery, \n",
    "# from highest to lowest, what percent of weapons would you recover if you made the best x percent of stops?\n",
    "# The plot should have percent of stops on the x axis and percent weapons recovered on the y axis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# HINTS:\n",
    "# 1) order results by column 'preds'\n",
    "results = results.sort(['preds'], ascending=False)\n",
    "\n",
    "# 2) add a column to results which is the cumulative sum of found.weapon_True\n",
    "plot_data = results[['found.weapon_True', 'preds']]\n",
    "plot_data['weap_sum'] = plot_data['found.weapon_True'].cumsum()\n",
    "\n",
    "\n",
    "\n",
    "# 3) use the above cumulative sum to make a column which shows percent weapons recovered\n",
    "plot_data['weap_perc'] = 100*plot_data['weap_sum']/plot_data['found.weapon_True'].sum()\n",
    "\n",
    "\n",
    "# 4) add a column which counts the stops\n",
    "s = [j for j in range(1,296522)]\n",
    "plot_data['nstop'] = s\n",
    "\n",
    "# 5) use the above stop count column to make a column which shows percent of all stops\n",
    "plot_data['stop_perc'] = 100*plot_data['nstop']/plot_data.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "# 6) restrict to just the columns from 3) and 5), downsample to maybe 1000 rows\n",
    "plot_data = plot_data[['stop_perc', 'weap_perc']]\n",
    "rows = random.sample(plot_data.index, 1000)\n",
    "plot_data = plot_data.ix[rows]\n",
    "\n",
    "\n",
    "\n",
    "# 7) sort everything in ascending order by the column from 5), then plot.\n",
    "plot_data = plot_data.sort(['stop_perc'], ascending=True)\n",
    "\n",
    "plt.figure()\n",
    "plot_data.plot(x='stop_perc', y='weap_perc')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
